# Project: Agentic AI — Email Extraction, Classification & Verification Pipeline for Assignment 1

## Purpose

Turn messy inbox email receipts (HTML or text) into clean, structured JSON for analysis or downstream systems, specifically tailored to match the gold schema provided in Assignment 1.

## Dataset Included

- `emails/` — Directory containing pairs of HTML and text files per email message (e.g., `1.html` and `1.txt`), redacted for privacy.
- `predictions.jsonl` — Output file with one JSON object per line, generated by the pipeline.

## What the Pipeline Does (High-Level)

- Processes each email pair (HTML + text) to extract structured data.
- Ignores decoy sections labeled Draft/Preview/Proforma/Projected/Forecast.
- Classifies emails into one of: `stripe_udemyx_receipt`, `google_play_subscription`, `shophive_order_confirmation`, `meta_instagram_receipt`, or `other`.
- Extracts structured fields per template as specified in the assignment schemas.
- Runs a verification/fix step to ensure schema compliance.
- Outputs one JSONL line per email in the format:
  {"id": int, "template": "string", "pred": {...}}
  text## Why This Is Useful
- Saves time: Automates manual reading and tagging of email receipts.
- Enables data analysis: Extracted fields (e.g., amounts, dates) become searchable and aggregatable.
- Ensures accuracy: Matches the exact gold schema for grading.

## Included Prompts

- `prompts.md` contains the exact classification, per-template extraction, and verification prompts used in the pipeline.
- Prompts are structured with role headers, delimiters, and strict JSON-only output instructions to align with Assignment 1 requirements.

## Files in This Repo (What to Open First)

- `extractor.py` — Main pipeline script (Groq-compatible variant included, adapted from `index.py`).
- `emails/` — Demo dataset directory with redacted email pairs.
- `predictions.jsonl` — Output file for submission.
- `prompts.md` — All prompt templates for classification, extraction, and verification.
- `prompt_evolution.md` — Log of prompt/rule evolution for grading.

## Quick Start (Run Locally)

### Install Dependencies

pip install -r requirements.txt
text- `requirements.txt` includes: `beautifulsoup4`, `groq`, `python-dotenv`.

### Configure Environment

- Create a `.env` file with your Groq API key:
  GROQ_API_KEY=your_key_here
  text- Optionally set models (defaults in script):
  GROQ_MODEL=openai/gpt-oss-120b
  text### Run the Pipeline
  python extractor.py
  text- The script processes all email pairs in the `emails/` directory and outputs to `predictions.jsonl`.
- Add a `--limit 10` argument to test with a subset (modify script to support this if needed).

## Model Guidance & Pitfalls

- Use a currently supported Groq model (e.g., `mixtral-8x7b-32768` or `llama3-70b-8192`).
- Pitfalls: Ensure HTML normalization handles zero-width spaces and wrapped digits; verify LLM output matches exact schemas.

## Assignment 1 Specifics

- **Input**: One HTML + one text file per email message.
- **Schemas**: Extract fields as shown in the assignment (e.g., `stripe_udemyx_receipt`, `google_play_subscription`, etc.).
- **Output**: `predictions.jsonl` with exact field names, types, and nesting.
- **Decoys & Gotchas**: Ignore decoy sections; normalize HTML before parsing.
- **Grading**: 70% accuracy (exact match on every field), 20% for gold evaluation, 30% for prompt evolution log.
- **Submission Checklist**: `predictions.jsonl` (required), `prompt_evolution.md`.

## Example Output Line (for Shape Only)

{
"id": 12,
"template": "stripe_udemyx_receipt",
"pred": {
"merchant": "UdemyX",
"receipt_number": "1589-0578",
"amount_paid_usd": 99.75,
"date_paid": "May 16, 2022",
"payment_last4": "1234",
"line_items": [
{ "description": "Deep Learning Nanodegree", "period": "2022-05-17—2022-06-17", "amount_usd": 99.75 }
]
}
}
